---
title: "P8105 Hw6"
output: github_document
---

```{r setup}
library(tidyverse)
library(readr)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1

Firstly load and clean the data

```{r}
birthweight = read_csv("./data/birthweight.csv")

birthweight = 
  birthweight %>% 
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = fct_recode(frace, "White" = "1", "Black" = "2", "Asian" = "3", 
                       "Puerto Rican" = "4", "Other" = "8", "Unkonwn" = "9"),
    malform = fct_recode(malform, "absent" = "0", "present" = "1"),
    mrace = fct_recode(mrace, "White" = "1", "Black" = "2", "Asian" = "3",
                       "Puerto Rican" = "4", "Other" = "8")
  )
```

Make a regression model

Since there are lots of variables, would try to use backward elimination

```{r}
# fit the regression, full model
mult.fit = lm(bwt ~ ., data = birthweight)
mult.fit %>% 
  broom::tidy()
```

```{r}
# backward elimination
back_fit = step(mult.fit, direction = 'backward')

back_fit %>% 
  broom::tidy()
```

So these are the prediction variables that my model contains.